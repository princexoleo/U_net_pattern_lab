{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "u_net_dev_from_scratch_with_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP85ibIxY1hHr0Ri/tPdDdj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/princexoleo/u_net_pattern_lab/blob/master/u_net_original_from_scratch_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30_SoM_QCrJB",
        "colab_type": "text"
      },
      "source": [
        "#U-Net Architechture Development with PyTorch framework\n",
        "* In this notebook I'll show how to implements U-Net architecture which shown in original papers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n711K3SCCkf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import necessary libraries and module\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyEgqTKjDW_j",
        "colab_type": "text"
      },
      "source": [
        "##Create simple class called U-Net\n",
        "* 2D Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU82_BVODlO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As we need a dounble convolution operation, so I create double conv function\n",
        "def double_conv(input_channel, output_channel):\n",
        "  conv = nn.Sequential(\n",
        "      nn.Conv2d(input_channel, output_channel, kernel_size=3),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(output_channel, output_channel, kernel_size=3),\n",
        "      nn.ReLU(inplace=True)\n",
        "  )\n",
        "  return conv\n",
        "\n",
        "\n",
        "def crop_img(org_tensor, target_tensor):\n",
        "  target_size = target_tensor.size()[2]\n",
        "  org_tensor_size = org_tensor.size()[2]\n",
        "  delta = org_tensor_size - target_size\n",
        "  delta = delta // 2\n",
        "  return org_tensor[:,:, delta:org_tensor_size-delta, delta:org_tensor_size-delta]\n"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC4axpuoDN8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self, input_c, num_class):\n",
        "    super(UNet, self).__init__()\n",
        "    self.input_c = input_c\n",
        "    self.num_class = num_class\n",
        "\n",
        "    self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.down_conv1 = double_conv(input_c, 64)\n",
        "    self.down_conv2 = double_conv(64, 128)\n",
        "    self.down_conv3 = double_conv(128, 256)\n",
        "    self.down_conv4 = double_conv(256, 512)\n",
        "    self.down_conv5 = double_conv(512, 1024)\n",
        "    ##\n",
        "    # Starting 2nd part of(expansion part)\n",
        "    # First we need transpose\n",
        "    self.up_trans_1 = nn.ConvTranspose2d(\n",
        "        in_channels=1024,\n",
        "        out_channels = 512,\n",
        "        kernel_size = 2,\n",
        "        stride = 2\n",
        "    )\n",
        "    self.up_conv_1 = double_conv(1024, 512)\n",
        "\n",
        "    self.up_trans_2 = nn.ConvTranspose2d(\n",
        "        in_channels=512,\n",
        "        out_channels = 256,\n",
        "        kernel_size = 2,\n",
        "        stride = 2\n",
        "    )\n",
        "    self.up_conv_2 = double_conv(512, 256)\n",
        "\n",
        "    self.up_trans_3 = nn.ConvTranspose2d(\n",
        "        in_channels=256,\n",
        "        out_channels = 128,\n",
        "        kernel_size = 2,\n",
        "        stride = 2\n",
        "    )\n",
        "    self.up_conv_3 = double_conv(256, 128)\n",
        "\n",
        "    self.up_trans_4 = nn.ConvTranspose2d(\n",
        "        in_channels=128,\n",
        "        out_channels = 64,\n",
        "        kernel_size = 2,\n",
        "        stride = 2\n",
        "    )\n",
        "    self.up_conv_4 = double_conv(128, 64)\n",
        "\n",
        "\n",
        "    ## Output layer\n",
        "    self.out = nn.Conv2d(\n",
        "        in_channels=64,\n",
        "        out_channels = 2,\n",
        "        kernel_size= 1\n",
        "    )\n",
        "\n",
        "  def forward(self, img):\n",
        "    # expected size (batch_size, in_channel, height, width)\n",
        "    print(\"Input: {}\".format(img.size()))\n",
        "    # encoder\n",
        "    x1 = self.down_conv1(img) #\n",
        "    x2 = self.max_pool_2x2(x1)\n",
        "    x3 = self.down_conv2(x2) #\n",
        "    x4 = self.max_pool_2x2(x3)\n",
        "    x5 = self.down_conv3(x4) #\n",
        "    x6 = self.max_pool_2x2(x5)\n",
        "    x7 = self.down_conv4(x6) #\n",
        "    x8 = self.max_pool_2x2(x7)\n",
        "    x9 = self.down_conv5(x8) \n",
        "    #x2 = self.max_pool_2x2(x9)\n",
        "    #print(x9.size())\n",
        "    # decoder\n",
        "    # now we need to concat tensor\n",
        "    # before concat we need to crop image/ pad image [original paper they crop]\n",
        "    x = self.up_trans_1(x9)\n",
        "    y = crop_img(x7, x)\n",
        "    x = self.up_conv_1(torch.cat([x,y], 1))\n",
        "    # print(x.size())\n",
        "\n",
        "    x = self.up_trans_2(x)\n",
        "    y = crop_img(x5, x)\n",
        "    x = self.up_conv_2(torch.cat([x,y], 1))\n",
        "\n",
        "\n",
        "    x = self.up_trans_3(x)\n",
        "    y = crop_img(x3, x)\n",
        "    x = self.up_conv_3(torch.cat([x,y], 1))\n",
        "\n",
        "    x = self.up_trans_4(x)\n",
        "    y = crop_img(x1, x)\n",
        "    x = self.up_conv_4(torch.cat([x,y], 1))\n",
        "\n",
        "    ##\n",
        "    logits = self.out(x)\n",
        "    print(\"Out: {}\".format(logits.size()))\n",
        "  "
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUscLOiMGYQn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7279922c-3a98-4cf0-dbb5-feddf66946e1"
      },
      "source": [
        "sample_img = torch.rand((1,1,572,572))\n",
        "unet_model = UNet(1, 2)\n",
        "#net_model\n",
        "## apply sample image with unet\n",
        "unet_model(sample_img)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: torch.Size([1, 1, 572, 572])\n",
            "Out: torch.Size([1, 2, 388, 388])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhC-bdjKM1W3",
        "colab_type": "text"
      },
      "source": [
        "##UNet: Covolutation1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGkNRVMTM5nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As we need a dounble convolution operation, so I create double conv function\n",
        "def double_conv(input_channel, output_channel):\n",
        "  conv = nn.Sequential(\n",
        "      nn.Conv1d(input_channel, output_channel, kernel_size=3,padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv1d(output_channel, output_channel, kernel_size=3, padding=1),\n",
        "      nn.ReLU(inplace=True)\n",
        "  )\n",
        "  return conv\n",
        "\n",
        "def crop_tensor(x1,x2):\n",
        "  diffY = x2.size()[1] - x1.size()[1]\n",
        "  diffX = x2.size()[2] - x1.size()[2]\n",
        "\n",
        "  x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "  return x1\n"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2sOEDMlR9qa",
        "colab_type": "text"
      },
      "source": [
        "###U-NET Model with 1D Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkMGRBQ5NXF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UNet_1D(nn.Module):\n",
        "  def __init__(self, input_c, num_class):\n",
        "    super(UNet_1D, self).__init__()\n",
        "    self.input_c = input_c\n",
        "    self.num_class = num_class\n",
        "\n",
        "    self.max_pool_2x2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "    self.down_conv1 = double_conv(input_c, 64)\n",
        "    self.down_conv2 = double_conv(64, 128)\n",
        "    self.down_conv3 = double_conv(128, 256)\n",
        "    self.down_conv4 = double_conv(256, 512)\n",
        "    self.down_conv5 = double_conv(512, 1024)\n",
        "    ##\n",
        "    # Starting 2nd part of(expansion part)\n",
        "    # First we need transpose\n",
        "    self.up_trans_1 = nn.ConvTranspose1d(\n",
        "        in_channels=1024,\n",
        "        out_channels = 512,\n",
        "        kernel_size = 2,\n",
        "        stride = 2,\n",
        "        output_padding = 1\n",
        "    )\n",
        "    self.up_conv_1 = double_conv(1024, 512)\n",
        "\n",
        "    self.up_trans_2 = nn.ConvTranspose1d(\n",
        "        in_channels=512,\n",
        "        out_channels = 256,\n",
        "        kernel_size = 2,\n",
        "        stride = 2,\n",
        "        output_padding = 1\n",
        "    )\n",
        "    self.up_conv_2 = double_conv(512, 256)\n",
        "\n",
        "    self.up_trans_3 = nn.ConvTranspose1d(\n",
        "        in_channels=256,\n",
        "        out_channels = 128,\n",
        "        kernel_size = 2,\n",
        "        stride = 2,\n",
        "        output_padding = 1\n",
        "    )\n",
        "    self.up_conv_3 = double_conv(256, 128)\n",
        "\n",
        "    self.up_trans_4 = nn.ConvTranspose1d(\n",
        "        in_channels=128,\n",
        "        out_channels = 64,\n",
        "        kernel_size = 2,\n",
        "        stride = 2,\n",
        "        padding = 1\n",
        "        \n",
        "    )\n",
        "    self.up_conv_4 = double_conv(128, 64)\n",
        "\n",
        "\n",
        "    ## Output layer\n",
        "    self.out = nn.Conv1d(\n",
        "        in_channels=64,\n",
        "        out_channels = self.num_class,\n",
        "        kernel_size= 1,\n",
        "    )\n",
        "\n",
        "  def forward(self, img):\n",
        "    # expected size (batch_size, in_channel, seq_length)\n",
        "    print(\"Input: {}\".format(img.size()))\n",
        "    # encoder\n",
        "    x1 = self.down_conv1(img) #\n",
        "    x2 = self.max_pool_2x2(x1)\n",
        "    x3 = self.down_conv2(x2) #\n",
        "    x4 = self.max_pool_2x2(x3)\n",
        "    x5 = self.down_conv3(x4) #\n",
        "    x6 = self.max_pool_2x2(x5)\n",
        "    x7 = self.down_conv4(x6) #\n",
        "    x8 = self.max_pool_2x2(x7)\n",
        "    x9 = self.down_conv5(x8) \n",
        "    #x2 = self.max_pool_2x2(x9)\n",
        "    #print(x9.size())\n",
        "    # decoder\n",
        "    # now we need to concat tensor\n",
        "    # before concat we need to crop image/ pad image [original paper they crop]\n",
        "    x = self.up_trans_1(x9)\n",
        "    y = crop_tensor(x7, x)\n",
        "    x = self.up_conv_1(torch.cat([x,y], 1))\n",
        "    # print(x.size())\n",
        "\n",
        "    x = self.up_trans_2(x)\n",
        "    y = crop_tensor(x5, x)\n",
        "    x = self.up_conv_2(torch.cat([x,y], 1))\n",
        "\n",
        "\n",
        "    x = self.up_trans_3(x)\n",
        "    y = crop_tensor(x3, x)\n",
        "    x = self.up_conv_3(torch.cat([x,y], 1))\n",
        "\n",
        "    x = self.up_trans_4(x)\n",
        "    y = crop_tensor(x1, x)\n",
        "    x = self.up_conv_4(torch.cat([x,y], 1))\n",
        "\n",
        "    ##\n",
        "    logits = self.out(x)\n",
        "    print(\"Out: {}\".format(logits.size()))\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPtxtfXtN1b7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a81e2201-6561-4351-b9e7-4bad9e4ee43b"
      },
      "source": [
        "# (batch_size, in_channell, seq_length)\n",
        "sample_input = torch.rand((1,42,700))\n",
        "unet_1D_model = UNet_1D(42, 8)\n",
        "#net_model\n",
        "unet_1D_model(sample_input)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: torch.Size([1, 42, 700])\n",
            "Out: torch.Size([1, 8, 700])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYhBgl_NOpyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}